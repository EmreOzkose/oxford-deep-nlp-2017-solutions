{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step0: dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import re\n",
    "from gensim.models import KeyedVectors\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import lxml.etree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step1: load data\n",
    "output:  \n",
    "**input_texts**: list of 2085 talk transcriptions (entire text, not tokenized, mixed case, punctuation etc.)  \n",
    "**labels**: corresponding list of 2085 strings containing several keywords each  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download the dataset if it's not already there\n",
    "if not os.path.isfile('ted_en-20160408.zip'):\n",
    "    urllib.request.urlretrieve(\"https://wit3.fbk.eu/get.php?path=XML_releases/xml/ted_en-20160408.zip&filename=ted_en-20160408.zip\", filename=\"ted_en-20160408.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract both the texts and the labels from the xml file\n",
    "with zipfile.ZipFile('ted_en-20160408.zip', 'r') as z:\n",
    "    doc = lxml.etree.parse(z.open('ted_en-20160408.xml', 'r'))\n",
    "input_texts = doc.xpath('//content/text()')\n",
    "labels = doc.xpath('//head/keywords/text()')\n",
    "del doc\n",
    "#print(input_texts[0])\n",
    "#print(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step2: preprocessing inputs and labels and building embeddings\n",
    "output:  \n",
    "**inputs_train**: list of 1585 tuples of (token_list, label_integer) for training  \n",
    "**inputs_test**: list of 250 tuples of (token_list, label_integer) for testing  \n",
    "**inputs_cv**: list of 250 tuples of (token_list, label_integer) for cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2085"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess the texts: lowercase, remove text in parentheses, remove punctuation, tokenize into words (split on whitespace)\n",
    "#removing text in parentheses\n",
    "input_texts = [re.sub(r'\\([^)]*\\)', '', input_text) for input_text in input_texts]\n",
    "#lowercase\n",
    "input_texts = [input_text.lower() for input_text in input_texts]\n",
    "#remove punctuation\n",
    "input_texts = [re.sub(r'[^a-z0-9]+', ' ', input_text) for input_text in input_texts]\n",
    "input_texts = [re.sub(r'[0-9]+', 'number_token', input_text) for input_text in input_texts]\n",
    "#tokenize into words\n",
    "input_texts = [input_text.split() for input_text in input_texts]\n",
    "len(input_texts)\n",
    "#input_texts[0][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4474850 words in the dataset.\n",
      "There are 17997 words that appear only once.\n",
      "There are now only 2363349 words in the dataset.\n"
     ]
    }
   ],
   "source": [
    "#get list of all words, and feed them into a Counter\n",
    "all_words = [word for input_text in input_texts for word in input_text]\n",
    "print(\"There are {} words in the dataset.\".format(len(all_words)))\n",
    "all_words_counter = collections.Counter(all_words)\n",
    "\n",
    "#remove some noise, take away the 50 most common and all words that only appear once\n",
    "#all_words_counter.most_common()[-100:-1] #100 least common\n",
    "#all_words_counter.most_common(50) #50 most common\n",
    "#[word for word_count_pair in all_words_counter.most_common() if word_count_pair[1] == 1] #all with a count of only one\n",
    "only_once = [word_count_pair[0] for word_count_pair in all_words_counter.most_common() if word_count_pair[1] == 1]\n",
    "print(\"There are {} words that appear only once.\".format(len(only_once)))\n",
    "\n",
    "to_remove = only_once\n",
    "#TODO: this removes number_token also?\n",
    "to_remove += [word_count_pair[0] for word_count_pair in all_words_counter.most_common(50)]\n",
    "\n",
    "#############WARNING!##############\n",
    "#this step took ~1h on my 2013 i5!\n",
    "test = [[word for word in input_text if word not in to_remove] for input_text in input_texts]\n",
    "\n",
    "new_all_words = [word for input_text in test for word in input_text]\n",
    "print(\"There are now only {} words in the dataset.\".format(len(new_all_words)))\n",
    "\n",
    "#input_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_texts = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#padding every text to the max text length for later batching\n",
    "l_max = max([len(text) for text in input_texts])\n",
    "for text in input_texts:\n",
    "    text += ['<PAD>'] * (l_max - len(text))\n",
    "#print(input_texts[0][-10:-1])\n",
    "#print(np.mean([len(text) for text in input_texts]) == l_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 3, 5, 0, 0, 0, 0, 5, 0, 3, 2, 5, 0, 0, 3, 0, 5, 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess the labels: search for occurences of the keywords \"technology\", \"entertainment\" or \"design\" and build labels\n",
    "label_lookup = ['ooo', 'Too', 'oEo', 'ooD', 'TEo', 'ToD', 'oED', 'TED']\n",
    "for i in range(len(labels)):\n",
    "    ted_labels = ['o', 'o', 'o']\n",
    "    keyword_list = labels[i].split(', ')\n",
    "    if 'technology' in keyword_list:\n",
    "        ted_labels[0] = 'T'\n",
    "    if 'entertainment' in keyword_list:\n",
    "        ted_labels[1] = 'E'\n",
    "    if 'design' in keyword_list:\n",
    "        ted_labels[2] = 'D'\n",
    "    labels[i] = ''.join(ted_labels)\n",
    "    labels[i] = label_lookup.index(labels[i])\n",
    "len(labels)\n",
    "labels[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating the unique vocabulary lookup\n",
    "vocab_list = list(set([word for input_text in input_texts for word in input_text]))\n",
    "word_to_index = {}\n",
    "index_to_word = {}\n",
    "for i, word in enumerate(vocab_list):\n",
    "    word_to_index[word] = i\n",
    "    index_to_word[i] = word\n",
    "input_indices_list = []\n",
    "for input_text in input_texts:\n",
    "    input_indices_list.append([word_to_index[word] for word in input_text])\n",
    "#del vocab_list\n",
    "#del input_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load glove word vectors\n",
    "glove = KeyedVectors.load_word2vec_format('glove.6B.50d.w2vformat.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 35665 words\n",
      "found 34494 word vectors, 0.9671666900322445 of our vocabulary\n",
      "missing words e.g. ['gorking', 'transgenesis', 'memorizer', 'acinus', 'randoms', 'hnumber_tokens', 'relaunchers', 'jacobaeus', 'gelem', 'reorientate', 'flyfire', 'genomically', 'monogamously', 'nehu', 'praxeology', 'ghemawat', 'otherizing', 'foldscope', 'corvisart', 'marseus', 'tilonia', 'cagoots', 'escalope', 'deoxyhemoglobin', 'pammy', 'number_tokenh', 'tedactive', 'sesfontein', 'mybo', 'soljacic', 'greenlab', 'tedyouth', 'bugness', 'supergays', 'paje', 'kamkwamba', 'retweeted', 'alaikum', 'deskbar', 'searchability', 'approtec', 'perony', 'pranitha', 'heforshe', 'pnumber_token', 'arghs', 'ockelford', 'dubowsky', 'shotglass', 'unignorable']\n"
     ]
    }
   ],
   "source": [
    "#creating embeddings, checking for each word in the input texts whether it is part of \n",
    "#the glove corpus, if yes intialize that row in the embeddings with the glove value, if\n",
    "#not initialize it uniformly between [-1.0, 1.0]\n",
    "voc_len = len(word_to_index)\n",
    "print(\"vocabulary size: {} words\".format(voc_len))\n",
    "counter = 0\n",
    "not_found_list = []\n",
    "embeddings = np.random.uniform(-1.0, 1.0, size=(voc_len, 50))\n",
    "for word, index in word_to_index.items():\n",
    "    if word in glove.vocab:\n",
    "        counter += 1\n",
    "        embeddings[index] = glove[word]\n",
    "    else:\n",
    "        not_found_list.append(word)\n",
    "print(\"found {} word vectors, {} of our vocabulary\".format(counter, float(counter)/voc_len))\n",
    "print(\"missing words e.g. {}\".format(not_found_list[0:50]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1585, 250, 250)\n"
     ]
    }
   ],
   "source": [
    "# combining the tokens and labels for each input, then shuffle them and split into train/test/cv\n",
    "inputs_combined = list(zip(input_indices_list, labels))\n",
    "shuffle(inputs_combined)\n",
    "inputs_train = inputs_combined[:1585]\n",
    "inputs_test = inputs_combined[1585:1835]\n",
    "inputs_cv = inputs_combined[1835:]\n",
    "print((len(inputs_train), len(inputs_test), len(inputs_cv)))\n",
    "#print(inputs_train[0])\n",
    "#print([index_to_word[i] for i in inputs_train[0][0]])\n",
    "#print([input_pair[1] for input_pair in inputs_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngIhIwBQCIiIBUwiIiARMISAiErD/B4wpkWddxCRzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd005049b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting a histogram over the label distribution in the entire dataset\n",
    "#as you can see 'ooo' is basically ~50% of the dataset, so an accuracy score\n",
    "#of 50% could be reached by simply learning to predict 'ooo' all the time (not good)\n",
    "Y_plot = np.histogram(labels, bins=8)[0]\n",
    "X_plot = np.arange(8)\n",
    "plt.bar(X_plot, +Y_plot, facecolor='#9999ff', edgecolor='white')\n",
    "for x,y in zip(X_plot,Y_plot):\n",
    "    plt.text(x, y+0.05, label_lookup[x], ha='center', va= 'bottom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step3: building the tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# building the tensorflow logistic regression model\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TextClassifier(object):\n",
    "    def __init__(self, lr, activation, train_algo, embeddings, train_embeddings, voc_len, embed_size, batch_size, hidden_units, classes):\n",
    "        #placeholders\n",
    "        #(batch_size left)\n",
    "        self.input_ph = tf.placeholder(tf.int32, shape=(None, None), name='input')\n",
    "        self.labels_ph = tf.placeholder(tf.int32, shape=(None, classes), name='labels')\n",
    "        self.dropout_ph = tf.placeholder(tf.float32, shape=(), name='dropout')  \n",
    "        \n",
    "        #embedding layer\n",
    "        with tf.device('/cpu:0'), tf.name_scope(\"embedding\"):\n",
    "            #depending on whether a pre-trained embedding is provided and whether or not\n",
    "            #the embedding should be trainable\n",
    "            if embeddings is not None and train_embeddings is True:\n",
    "                self.L = tf.Variable(embeddings, name=\"L\")\n",
    "            elif embeddings is not None and train_embeddings is False:\n",
    "                self.L = tf.constant(embeddings, name=\"L\")\n",
    "            else:\n",
    "                self.L = tf.Variable(tf.random_uniform([voc_len, embed_size], -1.0, 1.0), name=\"L\")\n",
    "            input_vectors = tf.nn.embedding_lookup(self.L, self.input_ph)\n",
    "            X = tf.squeeze(tf.reduce_mean(input_vectors, axis=1, keep_dims=True), axis=1)\n",
    "        \n",
    "        #network model\n",
    "        with tf.name_scope(\"network\"):\n",
    "            W1 = tf.Variable(tf.random_normal((embed_size, hidden_units), stddev=0.1), name=\"W1\")\n",
    "            b1 = tf.Variable(tf.zeros(hidden_units), name='b1')\n",
    "\n",
    "            self.W2 = tf.Variable(tf.random_normal((hidden_units, classes), stddev=0.1), name=\"W2\")\n",
    "            b2 = tf.Variable(tf.zeros(classes), name='b2')\n",
    "            \n",
    "            if activation == 'relu':\n",
    "                hidden = tf.nn.relu(tf.matmul(tf.cast(X, tf.float32), W1) + b1)\n",
    "            elif activation == 'tanh':\n",
    "                hidden = tf.nn.tanh(tf.matmul(tf.cast(X, tf.float32), W1) + b1)\n",
    "            else:\n",
    "                hidden = tf.nn.sigmoid(tf.matmul(tf.cast(X, tf.float32), W1) + b1)\n",
    "            hidden = tf.nn.dropout(hidden, self.dropout_ph)\n",
    "\n",
    "            output = tf.matmul(hidden, self.W2) + b2\n",
    "            output = tf.nn.dropout(output, self.dropout_ph)\n",
    "            #yhat = tf.nn.softmax(out) #no need to calc whole prob dist if we only want the argmax\n",
    "            self.predictions = tf.argmax(output, axis=1)\n",
    "        \n",
    "        #loss\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            self.losses = tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=self.labels_ph)\n",
    "            l2_loss = tf.nn.l2_loss(W1) + tf.nn.l2_loss(b1) + tf.nn.l2_loss(self.W2) + tf.nn.l2_loss(b2)\n",
    "            self.loss = tf.reduce_mean(self.losses) + (0.01 * l2_loss)\n",
    "            \n",
    "        #acc\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            correct_predictions = tf.equal(self.predictions, tf.argmax(self.labels_ph, axis=1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "            \n",
    "        #training operation\n",
    "        with tf.name_scope(\"training\"):\n",
    "            if train_algo == 'adam':\n",
    "                self.train_op = tf.train.AdamOptimizer(lr).minimize(self.loss)\n",
    "            elif train_algo == 'adagrad':\n",
    "                self.train_op = tf.train.AdagradOptimizer(lr).minimize(self.loss)\n",
    "            else:\n",
    "                self.train_op = tf.train.GradientDescentOptimizer(lr).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, nn, train_data, cv_data, test_data, batch_size, train_dropout, epochs):\n",
    "        self.nn = nn\n",
    "        self.train_data = train_data\n",
    "        self.cv_data = cv_data\n",
    "        self.test_data = test_data\n",
    "        self.batch_size = batch_size\n",
    "        self.train_dropout = train_dropout\n",
    "        self.epochs = epochs\n",
    "        self.W2, self.collect_preds, self.collect_truth = None, [], []\n",
    "\n",
    "    def _get_data_batch(self, curr_index, batch_size, data):\n",
    "        curr_batch = data[curr_index:curr_index+batch_size]\n",
    "        input_batch_list, labels_batch_list = zip(*curr_batch) #unzip the list of input pair tuples (text, label)\n",
    "        curr_input_batch = np.array(input_batch_list, dtype=np.int32)\n",
    "        one_hot = np.zeros((len(labels_batch_list), classes))            \n",
    "        one_hot[range(len(labels_batch_list)), labels_batch_list] = 1            \n",
    "        curr_labels_batch = one_hot\n",
    "        return curr_input_batch, curr_labels_batch\n",
    "    \n",
    "    def _print_status(self, epoch_loss, epoch_train_acc, epoch_cv_acc):\n",
    "        print (\"epoch train loss: {}, epoch train accuracy: {}, epoch cv accuracy: {} \".\n",
    "               format(np.mean(epoch_loss), np.mean(epoch_train_acc), np.mean(epoch_cv_acc)))#, end=\"\\r\")\n",
    "        \n",
    "    def run_epoch(self, sess):\n",
    "        self.W2 = None\n",
    "        epoch_loss, epoch_train_acc, epoch_cv_acc = [], [], []\n",
    "        #run training on the train data\n",
    "        curr_index = 0\n",
    "        while curr_index < len(self.train_data):\n",
    "            curr_input_batch, curr_labels_batch = self._get_data_batch(curr_index, self.batch_size, self.train_data)\n",
    "            feed_dict={self.nn.dropout_ph:self.train_dropout, \n",
    "                       self.nn.input_ph:curr_input_batch, \n",
    "                       self.nn.labels_ph:curr_labels_batch}\n",
    "            self.W2, c_loss, c_losses, c_train_acc, _ = sess.run([self.nn.W2, self.nn.loss, self.nn.losses, self.nn.accuracy, self.nn.train_op], feed_dict=feed_dict)\n",
    "            #print(c_losses)\n",
    "            #print(c_loss)\n",
    "            epoch_loss.append(c_loss)\n",
    "            epoch_train_acc.append(c_train_acc)\n",
    "            curr_index += self.batch_size\n",
    "        \n",
    "        #run cross evaluation on the cv data\n",
    "        curr_index = 0\n",
    "        while curr_index < len(self.cv_data):\n",
    "            curr_input_batch, curr_labels_batch = self._get_data_batch(curr_index, self.batch_size, self.cv_data)\n",
    "            feed_dict={self.nn.dropout_ph:1.0, \n",
    "                       self.nn.input_ph:curr_input_batch, \n",
    "                       self.nn.labels_ph:curr_labels_batch}\n",
    "            c_cv_acc = sess.run(self.nn.accuracy, feed_dict=feed_dict)\n",
    "            epoch_cv_acc.append(c_cv_acc)\n",
    "            curr_index += self.batch_size\n",
    "        \n",
    "        self._print_status(epoch_loss, epoch_train_acc, epoch_cv_acc)\n",
    "    \n",
    "    def train(self):\n",
    "        print(\"Starting training for {} epochs.\".format(self.epochs))\n",
    "        with tf.Session() as sess:\n",
    "            tf.global_variables_initializer().run()\n",
    "            for _ in range(self.epochs):\n",
    "                self.run_epoch(sess)\n",
    "            print(\"Done Training.\")\n",
    "            self._test(sess)\n",
    "        \n",
    "    def _test(self, sess):\n",
    "        print(\"Testing the trained model on the test set.\")\n",
    "        #would be better to choose the best model on cv for this instead of simply the one from the last iteration\n",
    "        curr_index = 0\n",
    "        epoch_test_acc = []\n",
    "        while curr_index < len(self.test_data):\n",
    "            curr_input_batch, curr_labels_batch = self._get_data_batch(curr_index, self.batch_size, self.test_data)\n",
    "            feed_dict={self.nn.dropout_ph:1.0, \n",
    "                       self.nn.input_ph:curr_input_batch, \n",
    "                       self.nn.labels_ph:curr_labels_batch}\n",
    "            c_test_acc, test_predictions = sess.run([self.nn.accuracy, self.nn.predictions], feed_dict=feed_dict)\n",
    "            epoch_test_acc.append(c_test_acc)\n",
    "            self.collect_preds.extend(test_predictions)\n",
    "            self.collect_truth.extend(np.argmax(curr_labels_batch, axis=1))\n",
    "            curr_index += self.batch_size\n",
    "        print(\"Test set accuracy: {}\".format(np.mean(epoch_test_acc)))\n",
    "        print(\"Done Testing.\")      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step4: model instantiation, training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 50 epochs.\n",
      "epoch train loss: 2.049983501434326, epoch train accuracy: 0.40089285373687744, epoch cv accuracy: 0.5239999890327454 \n",
      "epoch train loss: 1.6705362796783447, epoch train accuracy: 0.5112500190734863, epoch cv accuracy: 0.5399999618530273 \n",
      "epoch train loss: 1.4753882884979248, epoch train accuracy: 0.5799107551574707, epoch cv accuracy: 0.5800000429153442 \n",
      "epoch train loss: 1.3499927520751953, epoch train accuracy: 0.6247321367263794, epoch cv accuracy: 0.5760000348091125 \n",
      "epoch train loss: 1.3982343673706055, epoch train accuracy: 0.6270535588264465, epoch cv accuracy: 0.6000000238418579 \n",
      "epoch train loss: 1.2956435680389404, epoch train accuracy: 0.6383035778999329, epoch cv accuracy: 0.5680000185966492 \n",
      "epoch train loss: 1.1923316717147827, epoch train accuracy: 0.7072321772575378, epoch cv accuracy: 0.5680000185966492 \n",
      "epoch train loss: 1.0582771301269531, epoch train accuracy: 0.7407142519950867, epoch cv accuracy: 0.5920000076293945 \n",
      "epoch train loss: 1.0310413837432861, epoch train accuracy: 0.7625892162322998, epoch cv accuracy: 0.5679999589920044 \n",
      "epoch train loss: 0.9497240781784058, epoch train accuracy: 0.772232174873352, epoch cv accuracy: 0.5760000348091125 \n",
      "epoch train loss: 0.9122374653816223, epoch train accuracy: 0.7919642925262451, epoch cv accuracy: 0.5239999890327454 \n",
      "epoch train loss: 0.9061110615730286, epoch train accuracy: 0.7887499928474426, epoch cv accuracy: 0.5760000348091125 \n",
      "epoch train loss: 0.8825656175613403, epoch train accuracy: 0.789017915725708, epoch cv accuracy: 0.6000000238418579 \n",
      "epoch train loss: 0.8581994771957397, epoch train accuracy: 0.7986607551574707, epoch cv accuracy: 0.6079999804496765 \n",
      "epoch train loss: 0.7816299796104431, epoch train accuracy: 0.8330357074737549, epoch cv accuracy: 0.5839999914169312 \n",
      "epoch train loss: 0.7838374376296997, epoch train accuracy: 0.823035717010498, epoch cv accuracy: 0.5559999942779541 \n",
      "epoch train loss: 0.827121376991272, epoch train accuracy: 0.8083928823471069, epoch cv accuracy: 0.5759999752044678 \n",
      "epoch train loss: 0.7656433582305908, epoch train accuracy: 0.8182142972946167, epoch cv accuracy: 0.5800000429153442 \n",
      "epoch train loss: 0.792334794998169, epoch train accuracy: 0.8223214149475098, epoch cv accuracy: 0.5879999995231628 \n",
      "epoch train loss: 0.7716180086135864, epoch train accuracy: 0.8205357193946838, epoch cv accuracy: 0.5839999914169312 \n",
      "epoch train loss: 0.8075343370437622, epoch train accuracy: 0.8044643402099609, epoch cv accuracy: 0.5760000348091125 \n",
      "epoch train loss: 0.7684184312820435, epoch train accuracy: 0.8125, epoch cv accuracy: 0.5720000267028809 \n",
      "epoch train loss: 0.8047080039978027, epoch train accuracy: 0.8199999928474426, epoch cv accuracy: 0.5720000267028809 \n",
      "epoch train loss: 0.8093233108520508, epoch train accuracy: 0.822857141494751, epoch cv accuracy: 0.5679999589920044 \n",
      "epoch train loss: 0.8030990958213806, epoch train accuracy: 0.8212499618530273, epoch cv accuracy: 0.5800000429153442 \n",
      "epoch train loss: 0.8955722451210022, epoch train accuracy: 0.7981249690055847, epoch cv accuracy: 0.5399999618530273 \n",
      "epoch train loss: 0.8740482330322266, epoch train accuracy: 0.8172321319580078, epoch cv accuracy: 0.5879999995231628 \n",
      "epoch train loss: 0.8106757998466492, epoch train accuracy: 0.8125892877578735, epoch cv accuracy: 0.5559999942779541 \n",
      "epoch train loss: 0.7491037845611572, epoch train accuracy: 0.8237500190734863, epoch cv accuracy: 0.5400000214576721 \n",
      "epoch train loss: 0.8282956480979919, epoch train accuracy: 0.8091071844100952, epoch cv accuracy: 0.5 \n",
      "epoch train loss: 0.8481073975563049, epoch train accuracy: 0.8153570890426636, epoch cv accuracy: 0.5560000538825989 \n",
      "epoch train loss: 0.8854198455810547, epoch train accuracy: 0.7964285612106323, epoch cv accuracy: 0.5080000162124634 \n",
      "epoch train loss: 0.9403564929962158, epoch train accuracy: 0.7974107265472412, epoch cv accuracy: 0.527999997138977 \n",
      "epoch train loss: 0.9456911683082581, epoch train accuracy: 0.8011607527732849, epoch cv accuracy: 0.4959999918937683 \n",
      "epoch train loss: 0.8794686794281006, epoch train accuracy: 0.8238393068313599, epoch cv accuracy: 0.47600001096725464 \n",
      "epoch train loss: 0.9030059576034546, epoch train accuracy: 0.8018749952316284, epoch cv accuracy: 0.5239999890327454 \n",
      "epoch train loss: 0.8878945112228394, epoch train accuracy: 0.7998213768005371, epoch cv accuracy: 0.43599995970726013 \n",
      "epoch train loss: 0.9995806813240051, epoch train accuracy: 0.7959821224212646, epoch cv accuracy: 0.5720000267028809 \n",
      "epoch train loss: 0.9595118761062622, epoch train accuracy: 0.8010714650154114, epoch cv accuracy: 0.6000000238418579 \n",
      "epoch train loss: 0.8910194635391235, epoch train accuracy: 0.8141964077949524, epoch cv accuracy: 0.5479999780654907 \n",
      "epoch train loss: 0.8825750350952148, epoch train accuracy: 0.8133928775787354, epoch cv accuracy: 0.5119999647140503 \n",
      "epoch train loss: 0.9958746433258057, epoch train accuracy: 0.7927678823471069, epoch cv accuracy: 0.527999997138977 \n",
      "epoch train loss: 0.9863139390945435, epoch train accuracy: 0.8135713934898376, epoch cv accuracy: 0.3959999978542328 \n",
      "epoch train loss: 1.0215309858322144, epoch train accuracy: 0.7880356907844543, epoch cv accuracy: 0.5640000104904175 \n",
      "epoch train loss: 0.9573015570640564, epoch train accuracy: 0.8065178394317627, epoch cv accuracy: 0.6320000290870667 \n",
      "epoch train loss: 0.9366047382354736, epoch train accuracy: 0.8036607503890991, epoch cv accuracy: 0.5920000076293945 \n",
      "epoch train loss: 1.0765843391418457, epoch train accuracy: 0.7830356955528259, epoch cv accuracy: 0.5560000538825989 \n",
      "epoch train loss: 1.0310770273208618, epoch train accuracy: 0.8120535612106323, epoch cv accuracy: 0.5839999914169312 \n",
      "epoch train loss: 1.0620406866073608, epoch train accuracy: 0.8001785278320312, epoch cv accuracy: 0.5440000295639038 \n",
      "epoch train loss: 1.1838542222976685, epoch train accuracy: 0.8012499809265137, epoch cv accuracy: 0.6000000238418579 \n",
      "Done Training.\n",
      "Testing the trained model on the test set.\n",
      "Test set accuracy: 0.6639999747276306\n",
      "Done Testing.\n"
     ]
    }
   ],
   "source": [
    "#config\n",
    "embed_size = 50\n",
    "batch_size = 50\n",
    "hidden_units = 50\n",
    "learning_rate = 0.03\n",
    "voc_len = len(word_to_index)\n",
    "classes = len(label_lookup)\n",
    "\n",
    "\n",
    "#instantiate a network\n",
    "#this can now be tested with all kinds of configurations\n",
    "#'tanh', 'adam', dropout of 0.5 and a lr of 0.05 seems to work best for me\n",
    "nn = TextClassifier(\n",
    "    lr=learning_rate,\n",
    "    activation='tanh',\n",
    "    train_algo='adam',\n",
    "    embeddings=embeddings, #or embeddings=None\n",
    "    train_embeddings=True,\n",
    "    voc_len=voc_len,\n",
    "    embed_size=embed_size,\n",
    "    batch_size=batch_size,\n",
    "    hidden_units=hidden_units,\n",
    "    classes=classes\n",
    ")\n",
    "\n",
    "#instantiate a trainer, train the model on the train data and then run the test on the test data\n",
    "trainer = Trainer(\n",
    "    nn=nn,\n",
    "    train_data=inputs_train,\n",
    "    cv_data=inputs_cv,\n",
    "    test_data=inputs_test,\n",
    "    batch_size=batch_size,\n",
    "    train_dropout=0.5,\n",
    "    epochs=50\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fcfe26682e8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcfe808b710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.arange(9)\n",
    "plt.hist(np.array(trainer.collect_preds), bins, alpha=0.5, label='predictions')\n",
    "plt.hist(np.array(trainer.collect_truth), bins, alpha=0.5, label='truth')\n",
    "plt.legend(loc='upper right')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([144,  44,  18,  18,   2,  20,   2,   2]),\n",
       " array([ 0.   ,  0.875,  1.75 ,  2.625,  3.5  ,  4.375,  5.25 ,  6.125,  7.   ]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(trainer.collect_truth, bins=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step5: visualizing the hidden to output weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"764e547c-19cb-4230-acde-6d196509aa52\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "    window._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (window._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    window._bokeh_timeout = Date.now() + 5000;\n",
       "    window._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (window.Bokeh !== undefined) {\n",
       "      document.getElementById(\"764e547c-19cb-4230-acde-6d196509aa52\").textContent = \"BokehJS successfully loaded.\";\n",
       "    } else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    delete window._bokeh_onload_callbacks\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"764e547c-19cb-4230-acde-6d196509aa52\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '764e547c-19cb-4230-acde-6d196509aa52' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      document.getElementById(\"764e547c-19cb-4230-acde-6d196509aa52\").textContent = \"BokehJS is loading...\";\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((window.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i](window.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!window._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      window._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"764e547c-19cb-4230-acde-6d196509aa52\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "plot_W2 = tsne.fit_transform(trainer.W2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ooo', 'Too', 'oEo', 'ooD', 'TEo', 'ToD', 'oED', 'TED']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <div class=\"bk-plotdiv\" id=\"c0afc1a6-efc1-4dcd-beda-933cf90381e0\"></div>\n",
       "    </div>\n",
       "<script type=\"text/javascript\">\n",
       "  \n",
       "  (function(global) {\n",
       "    function now() {\n",
       "      return new Date();\n",
       "    }\n",
       "  \n",
       "    var force = false;\n",
       "  \n",
       "    if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "      window._bokeh_onload_callbacks = [];\n",
       "      window._bokeh_is_loading = undefined;\n",
       "    }\n",
       "  \n",
       "  \n",
       "    \n",
       "    if (typeof (window._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "      window._bokeh_timeout = Date.now() + 0;\n",
       "      window._bokeh_failed_load = false;\n",
       "    }\n",
       "  \n",
       "    var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "       \"<div style='background-color: #fdd'>\\n\"+\n",
       "       \"<p>\\n\"+\n",
       "       \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "       \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "       \"</p>\\n\"+\n",
       "       \"<ul>\\n\"+\n",
       "       \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "       \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "       \"</ul>\\n\"+\n",
       "       \"<code>\\n\"+\n",
       "       \"from bokeh.resources import INLINE\\n\"+\n",
       "       \"output_notebook(resources=INLINE)\\n\"+\n",
       "       \"</code>\\n\"+\n",
       "       \"</div>\"}};\n",
       "  \n",
       "    function display_loaded() {\n",
       "      if (window.Bokeh !== undefined) {\n",
       "        document.getElementById(\"c0afc1a6-efc1-4dcd-beda-933cf90381e0\").textContent = \"BokehJS successfully loaded.\";\n",
       "      } else if (Date.now() < window._bokeh_timeout) {\n",
       "        setTimeout(display_loaded, 100)\n",
       "      }\n",
       "    }\n",
       "  \n",
       "    function run_callbacks() {\n",
       "      window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "      delete window._bokeh_onload_callbacks\n",
       "      console.info(\"Bokeh: all callbacks have finished\");\n",
       "    }\n",
       "  \n",
       "    function load_libs(js_urls, callback) {\n",
       "      window._bokeh_onload_callbacks.push(callback);\n",
       "      if (window._bokeh_is_loading > 0) {\n",
       "        console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "        return null;\n",
       "      }\n",
       "      if (js_urls == null || js_urls.length === 0) {\n",
       "        run_callbacks();\n",
       "        return null;\n",
       "      }\n",
       "      console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "      window._bokeh_is_loading = js_urls.length;\n",
       "      for (var i = 0; i < js_urls.length; i++) {\n",
       "        var url = js_urls[i];\n",
       "        var s = document.createElement('script');\n",
       "        s.src = url;\n",
       "        s.async = false;\n",
       "        s.onreadystatechange = s.onload = function() {\n",
       "          window._bokeh_is_loading--;\n",
       "          if (window._bokeh_is_loading === 0) {\n",
       "            console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "            run_callbacks()\n",
       "          }\n",
       "        };\n",
       "        s.onerror = function() {\n",
       "          console.warn(\"failed to load library \" + url);\n",
       "        };\n",
       "        console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      }\n",
       "    };var element = document.getElementById(\"c0afc1a6-efc1-4dcd-beda-933cf90381e0\");\n",
       "    if (element == null) {\n",
       "      console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'c0afc1a6-efc1-4dcd-beda-933cf90381e0' but no matching script tag was found. \")\n",
       "      return false;\n",
       "    }\n",
       "  \n",
       "    var js_urls = [];\n",
       "  \n",
       "    var inline_js = [\n",
       "      function(Bokeh) {\n",
       "        (function() {\n",
       "          var fn = function() {\n",
       "            var docs_json = {\"7cebf958-e010-4ffe-b28c-0c3c464f090f\":{\"roots\":{\"references\":[{\"attributes\":{\"plot\":{\"id\":\"9cd8ea97-0cfd-4fce-865e-6c82cf04d57b\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"66f3c727-95b0-4585-b6be-9b3bee42bca1\",\"type\":\"BasicTicker\"}},\"id\":\"4b250eb3-e098-4842-ab2f-2a1076a804c0\",\"type\":\"Grid\"},{\"attributes\":{\"plot\":null,\"text\":\"word2vec T-SNE for most common words\"},\"id\":\"23043117-347d-43cd-9b79-efb619b8641e\",\"type\":\"Title\"},{\"attributes\":{\"callback\":null},\"id\":\"2a1d968e-3e91-47d8-9a4e-7fb18f6a48d1\",\"type\":\"DataRange1d\"},{\"attributes\":{\"formatter\":{\"id\":\"90efa3fd-b434-41d0-9f06-d7cc9e2fbb7a\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"9cd8ea97-0cfd-4fce-865e-6c82cf04d57b\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"66f3c727-95b0-4585-b6be-9b3bee42bca1\",\"type\":\"BasicTicker\"}},\"id\":\"79826c32-1949-43d4-83c4-0ac33229222b\",\"type\":\"LinearAxis\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":8},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"}},\"id\":\"032168f6-9125-489b-88ae-f3e2b40916b6\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"a1fc2ed9-37fa-4927-813c-2b4c7eaebbf6\",\"type\":\"ToolEvents\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"9cd8ea97-0cfd-4fce-865e-6c82cf04d57b\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"eb373cc4-b180-4783-94aa-80489098f13e\",\"type\":\"BasicTicker\"}},\"id\":\"ffccd937-0a0d-4320-8f1d-36485e5fd7cb\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"84a1aa9b-9679-4928-b75a-b0edd3cf2af2\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"plot\":{\"id\":\"9cd8ea97-0cfd-4fce-865e-6c82cf04d57b\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"943ad68e-3714-4da5-98ff-544608d82925\",\"type\":\"SaveTool\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"5e4e0fee-778c-4e93-9f6c-c94326d6daa5\",\"type\":\"PanTool\"},{\"id\":\"d7744bda-f98e-4006-87de-22516ace9baa\",\"type\":\"WheelZoomTool\"},{\"id\":\"a8e4ccd6-ddf8-4c45-80e5-bfbd12ef895a\",\"type\":\"ResetTool\"},{\"id\":\"943ad68e-3714-4da5-98ff-544608d82925\",\"type\":\"SaveTool\"}]},\"id\":\"3b7fcd7e-34cf-4da8-a14c-7f2a5bb65a2d\",\"type\":\"Toolbar\"},{\"attributes\":{\"plot\":{\"id\":\"9cd8ea97-0cfd-4fce-865e-6c82cf04d57b\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"source\":{\"id\":\"76aa20d6-caac-4493-8c2c-30d77acb3e8e\",\"type\":\"ColumnDataSource\"},\"text\":{\"field\":\"names\"},\"text_align\":\"center\",\"text_color\":{\"value\":\"#555555\"},\"text_font_size\":{\"value\":\"8pt\"},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"},\"y_offset\":{\"value\":6}},\"id\":\"880d7733-fcd0-41e1-b521-d81cc18933f5\",\"type\":\"LabelSet\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":8},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"}},\"id\":\"8b6185b6-0851-49b8-89cd-bde634c2eaf7\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"90efa3fd-b434-41d0-9f06-d7cc9e2fbb7a\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"eb373cc4-b180-4783-94aa-80489098f13e\",\"type\":\"BasicTicker\"},{\"attributes\":{\"below\":[{\"id\":\"79826c32-1949-43d4-83c4-0ac33229222b\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"52b0b810-350c-4e09-ae35-14978a61be5b\",\"type\":\"LinearAxis\"}],\"renderers\":[{\"id\":\"79826c32-1949-43d4-83c4-0ac33229222b\",\"type\":\"LinearAxis\"},{\"id\":\"4b250eb3-e098-4842-ab2f-2a1076a804c0\",\"type\":\"Grid\"},{\"id\":\"52b0b810-350c-4e09-ae35-14978a61be5b\",\"type\":\"LinearAxis\"},{\"id\":\"ffccd937-0a0d-4320-8f1d-36485e5fd7cb\",\"type\":\"Grid\"},{\"id\":\"b5fbe1cd-c2b3-4f00-a895-8908a51d0bf3\",\"type\":\"GlyphRenderer\"},{\"id\":\"880d7733-fcd0-41e1-b521-d81cc18933f5\",\"type\":\"LabelSet\"}],\"title\":{\"id\":\"23043117-347d-43cd-9b79-efb619b8641e\",\"type\":\"Title\"},\"tool_events\":{\"id\":\"a1fc2ed9-37fa-4927-813c-2b4c7eaebbf6\",\"type\":\"ToolEvents\"},\"toolbar\":{\"id\":\"3b7fcd7e-34cf-4da8-a14c-7f2a5bb65a2d\",\"type\":\"Toolbar\"},\"toolbar_location\":\"above\",\"x_range\":{\"id\":\"370c9b68-8dd5-4bc9-8ac9-07015457d1a9\",\"type\":\"DataRange1d\"},\"y_range\":{\"id\":\"2a1d968e-3e91-47d8-9a4e-7fb18f6a48d1\",\"type\":\"DataRange1d\"}},\"id\":\"9cd8ea97-0cfd-4fce-865e-6c82cf04d57b\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"plot\":{\"id\":\"9cd8ea97-0cfd-4fce-865e-6c82cf04d57b\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"a8e4ccd6-ddf8-4c45-80e5-bfbd12ef895a\",\"type\":\"ResetTool\"},{\"attributes\":{\"formatter\":{\"id\":\"84a1aa9b-9679-4928-b75a-b0edd3cf2af2\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"9cd8ea97-0cfd-4fce-865e-6c82cf04d57b\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"eb373cc4-b180-4783-94aa-80489098f13e\",\"type\":\"BasicTicker\"}},\"id\":\"52b0b810-350c-4e09-ae35-14978a61be5b\",\"type\":\"LinearAxis\"},{\"attributes\":{\"plot\":{\"id\":\"9cd8ea97-0cfd-4fce-865e-6c82cf04d57b\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"5e4e0fee-778c-4e93-9f6c-c94326d6daa5\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"66f3c727-95b0-4585-b6be-9b3bee42bca1\",\"type\":\"BasicTicker\"},{\"attributes\":{\"data_source\":{\"id\":\"76aa20d6-caac-4493-8c2c-30d77acb3e8e\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"032168f6-9125-489b-88ae-f3e2b40916b6\",\"type\":\"Circle\"},\"hover_glyph\":null,\"nonselection_glyph\":{\"id\":\"8b6185b6-0851-49b8-89cd-bde634c2eaf7\",\"type\":\"Circle\"},\"selection_glyph\":null},\"id\":\"b5fbe1cd-c2b3-4f00-a895-8908a51d0bf3\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"callback\":null},\"id\":\"370c9b68-8dd5-4bc9-8ac9-07015457d1a9\",\"type\":\"DataRange1d\"},{\"attributes\":{\"plot\":{\"id\":\"9cd8ea97-0cfd-4fce-865e-6c82cf04d57b\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"d7744bda-f98e-4006-87de-22516ace9baa\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"names\",\"x1\",\"x2\"],\"data\":{\"names\":[\"ooo\",\"Too\",\"oEo\",\"ooD\",\"TEo\",\"ToD\",\"oED\",\"TED\"],\"x1\":{\"__ndarray__\":\"0yuxRL8IJz+wDdbOAKkZP3s2K0PIWig/YF4STmzpGD/Y6VkR+snjvjVKUzM+8u4+AHw++O70Ez/Aa126/GQHPw==\",\"dtype\":\"float64\",\"shape\":[8]},\"x2\":{\"__ndarray__\":\"uh3Rh7cKBT8o5djo4RwtP0t1ds+sNRm/QmfxM8d07r7OohgnmXsFP5BSNKTV/SI/GUnVNpE+6j6nCQcGCZsBPw==\",\"dtype\":\"float64\",\"shape\":[8]}}},\"id\":\"76aa20d6-caac-4493-8c2c-30d77acb3e8e\",\"type\":\"ColumnDataSource\"}],\"root_ids\":[\"9cd8ea97-0cfd-4fce-865e-6c82cf04d57b\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.4\"}};\n",
       "            var render_items = [{\"docid\":\"7cebf958-e010-4ffe-b28c-0c3c464f090f\",\"elementid\":\"c0afc1a6-efc1-4dcd-beda-933cf90381e0\",\"modelid\":\"9cd8ea97-0cfd-4fce-865e-6c82cf04d57b\"}];\n",
       "            \n",
       "            Bokeh.embed.embed_items(docs_json, render_items);\n",
       "          };\n",
       "          if (document.readyState != \"loading\") fn();\n",
       "          else document.addEventListener(\"DOMContentLoaded\", fn);\n",
       "        })();\n",
       "      },\n",
       "      function(Bokeh) {\n",
       "      }\n",
       "    ];\n",
       "  \n",
       "    function run_inline_js() {\n",
       "      \n",
       "      if ((window.Bokeh !== undefined) || (force === true)) {\n",
       "        for (var i = 0; i < inline_js.length; i++) {\n",
       "          inline_js[i](window.Bokeh);\n",
       "        }if (force === true) {\n",
       "          display_loaded();\n",
       "        }} else if (Date.now() < window._bokeh_timeout) {\n",
       "        setTimeout(run_inline_js, 100);\n",
       "      } else if (!window._bokeh_failed_load) {\n",
       "        console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "        window._bokeh_failed_load = true;\n",
       "      } else if (force !== true) {\n",
       "        var cell = $(document.getElementById(\"c0afc1a6-efc1-4dcd-beda-933cf90381e0\")).parents('.cell').data().cell;\n",
       "        cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "      }\n",
       "  \n",
       "    }\n",
       "  \n",
       "    if (window._bokeh_is_loading === 0) {\n",
       "      console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "      run_inline_js();\n",
       "    } else {\n",
       "      load_libs(js_urls, function() {\n",
       "        console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "        run_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }(this));\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
    "           toolbar_location=\"above\",\n",
    "           title=\"word2vec T-SNE for most common words\")\n",
    "\n",
    "source = ColumnDataSource(data=dict(x1=plot_W2[:,0],\n",
    "                                    x2=plot_W2[:,1],\n",
    "                                    names=label_lookup))\n",
    "\n",
    "p.scatter(x=\"x1\", y=\"x2\", size=8, source=source)\n",
    "\n",
    "labels = LabelSet(x=\"x1\", y=\"x2\", text=\"names\", y_offset=6,\n",
    "                  text_font_size=\"8pt\", text_color=\"#555555\",\n",
    "                  source=source, text_align='center')\n",
    "p.add_layout(labels)\n",
    "\n",
    "show(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
